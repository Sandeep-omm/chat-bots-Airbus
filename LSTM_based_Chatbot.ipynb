{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandeep-omm/chat-bots-Airbus/blob/main/LSTM_based_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eZTspchHnPzV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "dataset={\n",
        "    \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"greeting\",\n",
        "      \"patterns\": [\"Hello\", \"Hi\", \"Hey\", \"Greetings\", \"Good morning\", \"Good evening\"],\n",
        "      \"responses\": [\"Hello! Welcome to Airbus. How can we assist you today?\", \"Hi there! Looking for information about Airbus?\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"about_airbus\",\n",
        "      \"patterns\": [\"Tell me about Airbus\", \"What does Airbus do?\", \"Give me an overview of Airbus\",\"What is Airbus?\", \"Tell me what Airbus does\", \"Give me details about Airbus\"],\n",
        "      \"responses\": [\"Airbus is a global leader in aerospace, defence, and related services, pioneering sustainable aviation and cutting-edge defence solutions.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"financials\",\n",
        "      \"patterns\": [\"What were Airbus' revenues in 2023?\", \"Tell me about Airbus' financial performance\"],\n",
        "      \"responses\": [\"Airbus reported revenues of â‚¬65.4 billion in 2023, with an EBIT Adjusted of â‚¬5.8 billion.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"sustainability\",\n",
        "      \"patterns\": [\"What is Airbus doing for sustainability?\", \"Tell me about Airbus' environmental goals\", \"How is Airbus reducing emissions?\"],\n",
        "      \"responses\": [\"Airbus is committed to sustainability through initiatives such as sustainable aviation fuel (SAF), hydrogen-powered aircraft projects, and reducing CO2 emissions in manufacturing.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"aircraft_orders\",\n",
        "      \"patterns\": [\"How many aircraft did Airbus deliver in 2023?\", \"What is Airbus' commercial aircraft order status?\"],\n",
        "      \"responses\": [\"Airbus delivered 735 commercial aircraft in 2023 and secured 2,094 net orders, maintaining strong demand in the market.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"defence_space\",\n",
        "      \"patterns\": [\"Tell me about Airbus Defence and Space\", \"What are Airbus' defence projects?\", \"What contracts did Airbus Defence sign?\"],\n",
        "      \"responses\": [\"In 2023, Airbus Defence and Space secured significant contracts, including Spainâ€™s purchase of 16 C295 aircraft and Germanyâ€™s renewal of an A400M support contract.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"helicopters\",\n",
        "      \"patterns\": [\"Does Airbus make helicopters?\", \"Tell me about Airbus Helicopters\", \"Which helicopters does Airbus manufacture?\"],\n",
        "      \"responses\": [\"Yes, Airbus Helicopters is a leading provider of rotorcraft, offering models like the H145 and H160, with strong demand from both civil and military markets.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"innovation\",\n",
        "      \"patterns\": [\"What innovations is Airbus working on?\", \"Tell me about Airbus' technology advancements\", \"Is Airbus working on hydrogen planes?\"],\n",
        "      \"responses\": [\"Airbus is pioneering future aerospace technologies, including hydrogen-powered aircraft (ZEROe project), AI-driven manufacturing, and advanced defence systems.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"strategy\",\n",
        "      \"patterns\": [\"What is Airbus' strategy for the future?\", \"Tell me about Airbus' business strategy\", \"How is Airbus planning for the future?\"],\n",
        "      \"responses\": [\"Airbus is focused on growth in commercial aviation, defence, and sustainability, investing in modernisation, digitalisation, and decarbonisation strategies.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"contact_info\",\n",
        "      \"patterns\": [\"How can I contact Airbus?\", \"Where is Airbus headquartered?\", \"What is Airbus' customer support contact?\"],\n",
        "      \"responses\": [\"Airbus SE is headquartered in Leiden, Netherlands. You can visit www.airbus.com for contact details and customer support.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"workforce\",\n",
        "      \"patterns\": [\"How many employees does Airbus have?\", \"Tell me about Airbus' workforce\", \"What is Airbus' workforce strength?\"],\n",
        "      \"responses\": [\"As of 2023, Airbus employs approximately 147,893 people worldwide, reflecting its growth and global presence.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_foundation\",\n",
        "      \"patterns\": [\"What is the Airbus Foundation?\", \"Tell me about Airbus' social impact initiatives\"],\n",
        "      \"responses\": [\"The Airbus Foundation focuses on humanitarian response, youth development, and environmental action, leveraging Airbus' technology for positive impact.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"digital_transformation\",\n",
        "      \"patterns\": [\"How is Airbus using digital technology?\", \"Tell me about Airbus' digital transformation\"],\n",
        "      \"responses\": [\"Airbus is advancing digitalisation through AI, automation, and smart manufacturing to enhance production efficiency and product innovation.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"future_aircraft\",\n",
        "      \"patterns\": [\"What are Airbus' future aircraft projects?\", \"Tell me about Airbus' next-generation planes\"],\n",
        "      \"responses\": [\"Airbus is working on the ZEROe hydrogen-powered aircraft, advanced A321XLR models, and AI-integrated aviation technologies.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_history\",\n",
        "      \"patterns\": [\"What is the history of Airbus?\", \"How was Airbus founded?\", \"Tell me about Airbusâ€™ origin\"],\n",
        "      \"responses\": [\"Airbus was founded through the merger of several European aerospace companies in 1970 and later became Airbus SE in 2015.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"founding_companies\",\n",
        "      \"patterns\": [\"Which companies merged to form Airbus?\", \"What are the founding companies of Airbus?\", \"Who created Airbus?\"],\n",
        "      \"responses\": [\"Airbus was formed from the merger of AÃ©rospatiale-Matra (France), DASA (Germany), and CASA (Spain).\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_headquarters\",\n",
        "      \"patterns\": [\"Where is Airbus headquarters?\", \"Where is Airbus based?\", \"What is Airbus' main office location?\"],\n",
        "      \"responses\": [\"Airbus SE is legally registered in Leiden, Netherlands, but its main operational office is in Blagnac, France.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_leadership\",\n",
        "      \"patterns\": [\"Who is the CEO of Airbus?\", \"Who leads Airbus?\", \"Tell me about Airbus' leadership\"],\n",
        "      \"responses\": [\"The current CEO of Airbus is Guillaume Faury. The company is also led by a management board and executive committee.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_aircraft\",\n",
        "      \"patterns\": [\"What planes does Airbus make?\", \"Tell me about Airbus aircraft\", \"List Airbus aircraft\"],\n",
        "      \"responses\": [\"Airbus manufactures several aircraft, including the A220, A320, A330, A350, and A380.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"first_aircraft\",\n",
        "      \"patterns\": [\"What was Airbus' first aircraft?\", \"Which was the first Airbus plane?\", \"Tell me about the Airbus A300\"],\n",
        "      \"responses\": [\"The first aircraft developed by Airbus was the A300, a twin-engine wide-body aircraft, introduced in 1972.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"a320_vs_a321\",\n",
        "      \"patterns\": [\"What is the difference between the A320 and A321?\", \"Compare A320 and A321\", \"Which is better, A320 or A321?\"],\n",
        "      \"responses\": [\"The A321 is a stretched version of the A320, offering more seating capacity and range compared to the A320.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"a350_details\",\n",
        "      \"patterns\": [\"Tell me about the Airbus A350\", \"What are the features of A350?\", \"How is A350 different from other Airbus planes?\"],\n",
        "      \"responses\": [\"The Airbus A350 is a wide-body twinjet aircraft made with carbon-fiber-reinforced polymers, offering high fuel efficiency and modern technology.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"a380_details\",\n",
        "      \"patterns\": [\"Tell me about the Airbus A380\", \"What is the biggest Airbus plane?\", \"Describe the A380\"],\n",
        "      \"responses\": [\"The Airbus A380 is the world's largest passenger airliner, featuring two full decks and four engines. However, production ended in 2021.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_military_aircraft\",\n",
        "      \"patterns\": [\"Does Airbus make military aircraft?\", \"Tell me about Airbus' military planes\", \"Which military aircraft does Airbus produce?\"],\n",
        "      \"responses\": [\"Yes, Airbus manufactures military aircraft like the A400M Atlas, C295, and aerial refueling tankers like the A330 MRTT.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_helicopters\",\n",
        "      \"patterns\": [\"Does Airbus make helicopters?\", \"Tell me about Airbus helicopters\", \"List Airbus helicopter models\"],\n",
        "      \"responses\": [\"Yes, Airbus Helicopters offers civilian and military rotorcraft, including the H125, H145, H160, and the Tiger attack helicopter.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_joint_ventures\",\n",
        "      \"patterns\": [\"What joint ventures does Airbus have?\", \"Tell me about Airbus' partnerships\", \"Which companies does Airbus partner with?\"],\n",
        "      \"responses\": [\"Airbus has partnerships in ATR (50%), ArianeGroup (50%), Eurofighter (46%), MBDA (37.5%), and NHIndustries (62.5%).\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_stock\",\n",
        "      \"patterns\": [\"Is Airbus a publicly traded company?\", \"Where is Airbus listed?\", \"Tell me about Airbus stocks\"],\n",
        "      \"responses\": [\"Yes, Airbus SE is publicly traded on stock exchanges in Paris, Frankfurt, and Madrid, and is part of the EURO STOXX 50 index.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_production_sites\",\n",
        "      \"patterns\": [\"Where does Airbus build its planes?\", \"Tell me about Airbus factories\", \"Where are Airbus assembly lines?\"],\n",
        "      \"responses\": [\"Airbus assembles aircraft in Toulouse (France), Hamburg (Germany), Seville (Spain), Tianjin (China), Mobile (USA), and Mirabel (Canada).\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_environment\",\n",
        "      \"patterns\": [\"Is Airbus environmentally friendly?\", \"What are Airbus' sustainability initiatives?\", \"Does Airbus use biofuels?\"],\n",
        "      \"responses\": [\"Airbus is working on sustainable aviation, including biofuels, electric aircraft, and hydrogen-powered concepts like the ZEROe aircraft.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_controversies\",\n",
        "      \"patterns\": [\"Has Airbus faced any scandals?\", \"What controversies has Airbus been involved in?\", \"Tell me about Airbus' legal issues\"],\n",
        "      \"responses\": [\"Airbus has faced bribery allegations, insider trading investigations, and disputes over government subsidies with Boeing.\"]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"airbus_future\",\n",
        "      \"patterns\": [\"What are Airbus' future plans?\", \"What is Airbus working on?\", \"Tell me about Airbus' future projects\"],\n",
        "      \"responses\": [\"Airbus is developing hydrogen-powered aircraft, advanced space technologies, and improved versions of current aircraft models.\"]\n",
        "    }\n",
        "]\n",
        "}\n",
        "with open('dataset.json','w') as f:\n",
        "    json.dump(dataset,f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C44zF0W3crAv",
        "outputId": "ea1bb502-d0c6-4459-b7c8-5ce6e66d4c32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the modules and libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvdwKKzFoSM6",
        "outputId": "9649ed2a-15c3-49f2-c369-eece52a05517"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "with open('dataset.json','r') as file:\n",
        "    data=json.load(file)"
      ],
      "metadata": {
        "id": "WP0xhl1zqlMq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "sentences, labels = [], []\n",
        "classes = []\n",
        "ignore_chars = ['?', '!', ',', '.']"
      ],
      "metadata": {
        "id": "_4g_VcTcrs6C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process dataset\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        word_list = nltk.word_tokenize(pattern)\n",
        "        words = [lemmatizer.lemmatize(w.lower()) for w in word_list if w not in ignore_chars]\n",
        "        sentences.append(\" \".join(words))\n",
        "        labels.append(intent['tag'])\n",
        "    if intent['tag'] not in classes:\n",
        "        classes.append(intent['tag'])\n",
        "\n",
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "id": "CXlGl1ChsU7O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "muTCta3Iu6Gf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to the same length\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "x_train = pad_sequences(sequences, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "OzQogFPwyTYV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numerical form\n",
        "label_dict = {label: index for index, label in enumerate(classes)}\n",
        "y_train = np.array([label_dict[label] for label in labels])"
      ],
      "metadata": {
        "id": "FOShE1-hy5FV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokenizer and classes\n",
        "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
        "pickle.dump(classes, open('classes.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "MMf5trNrb8P2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model with Embedding (Keras 3 Fix)\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word_index) + 1, output_dim=128, mask_zero=True),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(classes), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "qCIhDgrfcdes"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZSH-8g1ldMEF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=8, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D2dm0sPEdNca",
        "outputId": "4a5879d9-d6c9-4b4a-9a08-453f4ac7f5b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - accuracy: 0.0057 - loss: 3.4360\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.0822 - loss: 3.4280\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.1989 - loss: 3.4130\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3157 - loss: 3.3763\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2319 - loss: 3.2789\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2661 - loss: 2.9964\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2517 - loss: 2.4285\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3373 - loss: 2.1735\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.5213 - loss: 1.6977\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5062 - loss: 1.5859\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.6436 - loss: 1.4783\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6985 - loss: 1.2600\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7608 - loss: 0.9356\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8061 - loss: 0.9057\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8457 - loss: 0.7863\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8613 - loss: 0.5887\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8719 - loss: 0.5919\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8998 - loss: 0.5058\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9458 - loss: 0.3812\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9316 - loss: 0.3859\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9398 - loss: 0.3243\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9603 - loss: 0.2822\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9691 - loss: 0.1974\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9668 - loss: 0.1283\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9835 - loss: 0.1572\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9922 - loss: 0.0851\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9675 - loss: 0.1178\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9687 - loss: 0.1489\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9224 - loss: 0.1409\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9891 - loss: 0.0872\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9610 - loss: 0.1092\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9784 - loss: 0.0997\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9897 - loss: 0.0738\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9528 - loss: 0.0839\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9894 - loss: 0.0582\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9614 - loss: 0.1036\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9750 - loss: 0.0941\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9830 - loss: 0.0484\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9894 - loss: 0.0608\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9938 - loss: 0.0494\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9728 - loss: 0.0702\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9908 - loss: 0.0540\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9789 - loss: 0.0575\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9702 - loss: 0.0584\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9792 - loss: 0.0441\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9728 - loss: 0.0530\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9659 - loss: 0.0692\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9904 - loss: 0.0547\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9764 - loss: 0.0442\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9552 - loss: 0.0864\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9679 - loss: 0.0489\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9931 - loss: 0.0248\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9835 - loss: 0.0400\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9880 - loss: 0.0275\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9929 - loss: 0.0602\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9682 - loss: 0.0512\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9912 - loss: 0.0354\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9853 - loss: 0.0448\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9943 - loss: 0.0443\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0400\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9718 - loss: 0.0816\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9984 - loss: 0.0209\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0242\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9648 - loss: 0.0459\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9668 - loss: 0.0654\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9824 - loss: 0.0413\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9535 - loss: 0.0565\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9693 - loss: 0.0522\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9777 - loss: 0.0398\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9871 - loss: 0.0233\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9707 - loss: 0.0555\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9767 - loss: 0.0430\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9913 - loss: 0.0222\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9920 - loss: 0.0336\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9546 - loss: 0.0577\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9677 - loss: 0.0420\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9552 - loss: 0.0474\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9943 - loss: 0.0359\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9609 - loss: 0.0415\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9622 - loss: 0.0807\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9868 - loss: 0.0394\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9757 - loss: 0.0275\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9929 - loss: 0.0310\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0206\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9929 - loss: 0.0224\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9483 - loss: 0.0638\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9965 - loss: 0.0298\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9668 - loss: 0.0480\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9871 - loss: 0.0224\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9780 - loss: 0.0259\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9975 - loss: 0.0210\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9894 - loss: 0.0205\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9677 - loss: 0.0478\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9737 - loss: 0.0347\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9683 - loss: 0.0407\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9732 - loss: 0.0390\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9896 - loss: 0.0166\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9975 - loss: 0.0217\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9897 - loss: 0.0300\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9780 - loss: 0.0292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ee31bcc7b90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('chatbot_model.keras')  # Save in Keras 3 format"
      ],
      "metadata": {
        "id": "XDUKfHZpdkKy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(text):\n",
        "    words = [lemmatizer.lemmatize(w.lower()) for w in nltk.word_tokenize(text)]\n",
        "    seq = tokenizer.texts_to_sequences([\" \".join(words)])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_length,padding='post')\n",
        "\n",
        "    prediction = model.predict(padded_seq,verbose=0)[0]\n",
        "    tag = classes[np.argmax(prediction)]\n",
        "\n",
        "    for intent in data['intents']:\n",
        "        if intent['tag'] == tag:\n",
        "            return random.choice(intent['responses'])\n",
        "    return \"I'm not sure about that. Can you ask something else?\""
      ],
      "metadata": {
        "id": "nkrazWQOe890"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Chatbot is ready! Type 'exit' to stop.\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Thank you for using Airbus chatbot tool. Goodbye!\")\n",
        "            break\n",
        "        print(\"Bot: \",chatbot_response(user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_G9M99LgdFR",
        "outputId": "352dd8bb-7599-477c-c803-c0ec6cd1aec6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot is ready! Type 'exit' to stop.\n",
            "You: hii\n",
            "Bot:  Hello! Welcome to Airbus. How can we assist you today?\n",
            "You: exit\n",
            "Thank you for using Airbus chatbot tool. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit --quiet"
      ],
      "metadata": {
        "id": "eeMhXUvkiXZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71010c93-2852-4312-e279-59ec9da27af8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "model=load_model('chatbot_model.keras')\n",
        "tokenizer=pickle.load(open('tokenizer.pkl','rb'))\n",
        "classes=pickle.load(open('classes.pkl','rb'))\n",
        "\n",
        "with open('dataset.json','r') as file:\n",
        "    data=json.load(file)\n",
        "\n",
        "max_length=model.input_shape[1]\n",
        "\n",
        "def chatbot_response(text):\n",
        "    words = [lemmatizer.lemmatize(w.lower()) for w in nltk.word_tokenize(text)]\n",
        "    seq = tokenizer.texts_to_sequences([\" \".join(words)])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "\n",
        "    prediction = model.predict(padded_seq, verbose=0)[0]\n",
        "    tag = classes[np.argmax(prediction)]\n",
        "\n",
        "    for intent in data['intents']:\n",
        "        if intent['tag'] == tag:\n",
        "            return random.choice(intent['responses'])\n",
        "    return \"I'm not sure about that. Can you ask something else?\"\n",
        "\n",
        "# Streamlit App Setup\n",
        "st.set_page_config(page_title=\"Chatbot ğŸ¤–\", page_icon=\"ğŸ’¬\")\n",
        "st.title(\"ğŸ¤– LSTM Chatbot\")\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display past messages\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "# Chat input\n",
        "prompt = st.chat_input(\"Type your message...\")\n",
        "\n",
        "if prompt:\n",
        "    # Add user message\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    # Generate response\n",
        "    response = chatbot_response(prompt)\n",
        "\n",
        "    # Add bot message\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(response)"
      ],
      "metadata": {
        "id": "KyLeOd9fg716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc15ba8-76b8-4ed9-de95-ef9b89202039"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "6SIuR-BOlBZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe2771f-90ba-40f7-9145-e82376cde1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.150.154.172:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20G"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dI6Slpy8lOfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}